{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8dd3ec2b-f938-4903-957c-baf4b342f3be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a620cc4c-6008-41e1-bf41-8840116d53e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_pkl_dict(filename, folder):\n",
    "    with open(folder + filename, \"rb\") as f:\n",
    "        loaded_file = pickle.load(f)\n",
    "        return loaded_file\n",
    "    \n",
    "def dict_to_tensor(labels_features: dict):\n",
    "    labels_list = []\n",
    "    for label in sorted(labels_features.keys()):\n",
    "        labels_list.append(torch.tensor(np.repeat(label, len(labels_features[label]))))\n",
    "    return torch.cat(list(labels_features.values())), torch.cat(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "750251ba-cb69-45f2-9406-db393329f524",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_features_dict,\n",
    "            val_features_dict,\n",
    "            val_logits_dict,\n",
    "            test_features_dict,\n",
    "            test_logits_dict) = load_pkl_dict(\"../../experiment_data/dnn_output_openmax_cnn_eminst0.pkl\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fecc60b3-22d4-4487-a8ad-eef94e7070bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "torch.Size([5995, 500])\n",
      "torch.Size([5978, 500])\n",
      "torch.Size([5988, 500])\n",
      "torch.Size([5997, 500])\n",
      "torch.Size([5985, 500])\n",
      "torch.Size([5979, 500])\n",
      "torch.Size([5989, 500])\n",
      "torch.Size([5984, 500])\n",
      "torch.Size([5984, 500])\n",
      "torch.Size([5996, 500])\n"
     ]
    }
   ],
   "source": [
    "print(sorted(training_features_dict.keys()))\n",
    "for key in training_features_dict:\n",
    "    print(training_features_dict[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15a5a40b-0417-4bb7-a98a-ec9bde314aed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 9, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "# Assuming data is a numpy array of shape (60000, 500)\n",
    "data, labels  = dict_to_tensor(training_features_dict)\n",
    "data = data.detach().numpy()\n",
    "mavs = []\n",
    "for key in sorted(training_features_dict):\n",
    "    mask = labels == key\n",
    "    data_class = data[mask]\n",
    "    mav = np.mean(data_class, axis=1)\n",
    "    mavs.append(mav)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce967ee5-ec1f-4105-9f8a-107f3d047d4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m tsne \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      2\u001b[0m principalComponents \u001b[38;5;241m=\u001b[39m tsne\u001b[38;5;241m.\u001b[39mfit_transform(data)\n\u001b[0;32m----> 3\u001b[0m principalComponents_mavs \u001b[38;5;241m=\u001b[39m \u001b[43mtsne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmavs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/openset-imagenet-comparison/lib/python3.8/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/.conda/envs/openset-imagenet-comparison/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/openset-imagenet-comparison/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:1110\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;66;03m# TSNE.metric is not validated yet\u001b[39;00m\n\u001b[1;32m   1087\u001b[0m     prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m )\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit X into an embedded space and return that transformed output.\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \n\u001b[1;32m   1092\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;124;03m        Embedding of the training data in low-dimensional space.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params_vs_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X)\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n",
      "File \u001b[0;32m~/.conda/envs/openset-imagenet-comparison/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:820\u001b[0m, in \u001b[0;36mTSNE._check_params_vs_input\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_params_vs_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperplexity \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperplexity must be less than n_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "principalComponents = tsne.fit_transform(data)\n",
    "principalComponents_mavs = tsne.fit_transform(mavs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88447ea2-48e0-4e6e-b0c9-0f82c886a60d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a color map\n",
    "color_map = plt.cm.get_cmap('viridis', 10)\n",
    "colors = [color_map(i) for i in range(10)]\n",
    "\n",
    "# Create a list of colors for each point\n",
    "point_colors = [colors[i] for i in labels]\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i in range(10):\n",
    "    plt.scatter(principalComponents[labels == i, 0], principalComponents[labels == i, 1], color=colors[i], label=f'Class {i}')\n",
    "    plt.scatter(principalComponents[i, 0], principalComponents[i, 1], color='r', label=f'MAV {i}')\n",
    "\n",
    "plt.legend(title='Classes')\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326b5761-f331-447d-ae39-3fb7e1913235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openset-imagenet-comparison",
   "language": "python",
   "name": "openset-imagenet-comparison"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
